{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRnet_Models Alexnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e97eada47918456b950d4cb96b39d9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bc4d8f8365a45c2b078c24d26af8855",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_272c38bfa84d4666bf1fe9e5d1c3f23d",
              "IPY_MODEL_94756e74dc3143319a412f6a7baf1b96"
            ]
          }
        },
        "0bc4d8f8365a45c2b078c24d26af8855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "272c38bfa84d4666bf1fe9e5d1c3f23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_104dd591decb473bbd0fe13cd6c2cb6b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0946af67252f467b80103237d76cd54e"
          }
        },
        "94756e74dc3143319a412f6a7baf1b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8475935f96f14a9a994a95702c6137a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [00:22&lt;00:00, 10.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c57533049ccd4720ad5fa98272afbdee"
          }
        },
        "104dd591decb473bbd0fe13cd6c2cb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0946af67252f467b80103237d76cd54e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8475935f96f14a9a994a95702c6137a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c57533049ccd4720ad5fa98272afbdee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNGHUei1q4jv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "dd02cdac-95b8-48a4-99a1-61f058139ee9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_E0ZkySu6eb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "724629a0-e94e-48c4-b0cb-894d13ecde8c"
      },
      "source": [
        "!pip install git+https://github.com/ncullen93/torchsample\n",
        "!pip install tensorboardX \n",
        "#!pip install --upgrade torch\n",
        "!pip install torch==1.5.1+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!wget https://gist.githubusercontent.com/archie9211/ae3c8411da88ae8b2a05b0ee1a4fd412/raw/ee1a6e78fc498ad6d4830cd2eb6033839235ea8a/colab-ssh-jupyter.sh\n",
        "!pip install -U git+https://github.com/pytorch/vision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ncullen93/torchsample\n",
            "  Cloning https://github.com/ncullen93/torchsample to /tmp/pip-req-build-w2xyznnm\n",
            "  Running command git clone -q https://github.com/ncullen93/torchsample /tmp/pip-req-build-w2xyznnm\n",
            "Building wheels for collected packages: torchsample\n",
            "  Building wheel for torchsample (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchsample: filename=torchsample-0.1.3-cp36-none-any.whl size=43417 sha256=5bbcddac37a8f80e25ba3787dc4dd707471f2cd31c7885251f816454006e2599\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f8imob58/wheels/88/c7/72/14cd9a173eed1e29d0b17d866e7d9ee511d31a834aedd27489\n",
            "Successfully built torchsample\n",
            "Installing collected packages: torchsample\n",
            "Successfully installed torchsample-0.1.3\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (47.3.1)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 704.4MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision==0.6.0+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0+cu101) (7.0.0)\n",
            "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101\n",
            "--2020-06-21 13:29:35--  https://gist.githubusercontent.com/archie9211/ae3c8411da88ae8b2a05b0ee1a4fd412/raw/ee1a6e78fc498ad6d4830cd2eb6033839235ea8a/colab-ssh-jupyter.sh\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1125 (1.1K) [text/plain]\n",
            "Saving to: â€˜colab-ssh-jupyter.shâ€™\n",
            "\n",
            "colab-ssh-jupyter.s 100%[===================>]   1.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-21 13:29:35 (59.3 MB/s) - â€˜colab-ssh-jupyter.shâ€™ saved [1125/1125]\n",
            "\n",
            "Collecting git+https://github.com/pytorch/vision\n",
            "  Cloning https://github.com/pytorch/vision to /tmp/pip-req-build-wtjhob9q\n",
            "  Running command git clone -q https://github.com/pytorch/vision /tmp/pip-req-build-wtjhob9q\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0a0+cd2b7f0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0a0+cd2b7f0) (1.5.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0a0+cd2b7f0) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==0.7.0a0+cd2b7f0) (0.16.0)\n",
            "Building wheels for collected packages: torchvision\n",
            "  Building wheel for torchvision (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchvision: filename=torchvision-0.7.0a0+cd2b7f0-cp36-cp36m-linux_x86_64.whl size=7915597 sha256=32cfef698cc4a8d26706bf988a0151c8c0207b43ba05b2493093f1d45dd65386\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ydp3t4oh/wheels/46/b1/7a/c6b6a2d8276d68c5231436044279cd0cd3338b6560b2c14336\n",
            "Successfully built torchvision\n",
            "Installing collected packages: torchvision\n",
            "  Found existing installation: torchvision 0.6.0+cu101\n",
            "    Uninstalling torchvision-0.6.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Successfully installed torchvision-0.7.0a0+cd2b7f0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utDm6bILrCYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.autograd import Variable\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN8am-ngrQ8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MRNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = models.alexnet(pretrained=True)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.squeeze(x, dim=0) # only batch size 1 supported\n",
        "        x = self.model.features(x)\n",
        "        x = self.gap(x).view(x.size(0), -1)\n",
        "        x = torch.max(x, 0, keepdim=True)[0]\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX2A_1HMrVme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MRI_alex(nn.Module):\n",
        "  def __init__(self, training=True):\n",
        "    super().__init__()\n",
        "    self.axial_net = models.alexnet(pretrained=training)\n",
        "    self.sagit_net = models.alexnet(pretrained=training)\n",
        "    self.coron_net = models.alexnet(pretrained=training)\n",
        "\n",
        "    self.gap_axial = nn.AdaptiveAvgPool2d(1)\n",
        "    self.gap_sagit = nn.AdaptiveAvgPool2d(1) \n",
        "    self.gap_coron = nn.AdaptiveAvgPool2d(1)\n",
        "    self.classifier = nn.Linear(3*256, 1)\n",
        "\n",
        "  def forward(self,vol_axial, vol_sagit, vol_coron):\n",
        "    vol_axial = torch.squeeze(vol_axial, dim=0)\n",
        "    vol_sagit = torch.squeeze(vol_sagit, dim=0)\n",
        "    vol_coron = torch.squeeze(vol_coron, dim=0)\n",
        "\n",
        "    vol_axial = self.axial_net.features(vol_axial)\n",
        "    vol_sagit = self.sagit_net.features(vol_sagit)\n",
        "    vol_coron = self.coron_net.features(vol_coron)\n",
        "\n",
        "    vol_axial = self.gap_axial(vol_axial).view(vol_axial.size(0), -1)\n",
        "    x = torch.max(vol_axial, 0, keepdim=True)[0]\n",
        "\n",
        "    vol_sagit = self.gap_sagit(vol_sagit).view(vol_sagit.size(0), -1)\n",
        "    y = torch.max(vol_sagit, 0, keepdim=True)[0]\n",
        "\n",
        "    vol_coron = self.gap_coron(vol_coron).view(vol_coron.size(0), -1)\n",
        "    z = torch.max(vol_coron, 0, keepdim=True)[0]\n",
        "\n",
        "    w = torch.cat((x, y, z), 1)\n",
        "    out = self.classifier(w)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKYynazQVHIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomAffine(25, translate=(0.1, 0.1)),\n",
        "            transforms.ToTensor()\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UT8KmaYVztF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor()\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-7nLcYmWTlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(series):\n",
        "   series = torch.tensor(np.stack((series,)*3, axis=1))\n",
        "   series = np.dot(np.divide((series - series.min()) , (series.max() - series.min())) , MAX_PIXEL_VAL)\n",
        "   series = np.divide((series - MEAN) , STDDEV)\n",
        "   return series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVX6JB_NriNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 224\n",
        "MAX_PIXEL_VAL = 255\n",
        "MEAN = 58.09\n",
        "STDDEV = 49.73\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, datadir, tear_type, use_gpu , transform=None):\n",
        "        super().__init__()\n",
        "        self.use_gpu = use_gpu\n",
        "        label_dict = {}\n",
        "        self.paths = []\n",
        "        self.transform = transform\n",
        "        \n",
        "        abnormal_label_dict = {}\n",
        "        if datadir[-1]==\"/\":\n",
        "            datadir = datadir[:-1]\n",
        "        self.datadir = datadir\n",
        "        for i, line in enumerate(open(datadir+'-'+tear_type+'.csv').readlines()):\n",
        "            line = line.strip().split(',')\n",
        "            filename = line[0]\n",
        "            label = line[1]\n",
        "            label_dict[filename] = int(label)\n",
        "        \n",
        "\n",
        "        for i, line in enumerate(open(datadir+'-'+\"abnormal\"+'.csv').readlines()):\n",
        "            line = line.strip().split(',')\n",
        "            filename = line[0]\n",
        "            label = line[1]\n",
        "            abnormal_label_dict[filename] = int(label)\n",
        "\n",
        "        for filename in os.listdir(os.path.join(datadir, \"axial\")):\n",
        "            if filename.endswith(\".npy\"):\n",
        "                self.paths.append(filename)\n",
        "        \n",
        "        self.labels = [label_dict[path.split(\".\")[0]] for path in self.paths]\n",
        "        self.abnormal_labels = [abnormal_label_dict[path.split(\".\")[0]] for path in self.paths]\n",
        "\n",
        "        #neg_weight = np.mean(self.labels)\n",
        "        #self.weights = [neg_weight, 1 - neg_weight]\n",
        "\n",
        "        if tear_type != \"abnormal\":\n",
        "            temp_labels = [self.labels[i] for i in range(len(self.labels)) if self.abnormal_labels[i]==1]\n",
        "            neg_weight = np.mean(temp_labels)\n",
        "        else:\n",
        "            neg_weight = np.mean(self.labels)\n",
        "        \n",
        "        self.weights = [neg_weight, 1 - neg_weight]\n",
        "    \n",
        "\n",
        "    def weighted_loss(self, prediction, target):\n",
        "        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n",
        "        weights_tensor = torch.FloatTensor(weights_npy)\n",
        "        if self.use_gpu:\n",
        "            weights_tensor = weights_tensor.cuda()\n",
        "        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n",
        "        return loss\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.paths[index]\n",
        "        vol_axial = np.load(os.path.join(self.datadir, \"axial\", filename))\n",
        "        vol_sagit = np.load(os.path.join(self.datadir, \"sagittal\", filename))\n",
        "        vol_coron = np.load(os.path.join(self.datadir, \"coronal\", filename))\n",
        "\n",
        "\n",
        "        # axial\n",
        "        pad = int((vol_axial.shape[2] - INPUT_DIM)/2)\n",
        "        vol_axial = vol_axial[:,pad:-pad,pad:-pad]\n",
        "        #vol_axial = np.dot(np.divide((vol_axial - vol_axial.min()) , (vol_axial.max() - vol_axial.min())) , MAX_PIXEL_VAL)\n",
        "        #vol_axial = np.divide((vol_axial - MEAN) , STDDEV)\n",
        "        #vol_axial = np.stack((vol_axial,)*3, axis=1)\n",
        "        vol_axial = preprocess(vol_axial)\n",
        "        \n",
        "        vol_axial_tensor = torch.FloatTensor(vol_axial)\n",
        "          \n",
        "        \n",
        "        # sagittal\n",
        "        pad = int((vol_sagit.shape[2] - INPUT_DIM)/2)\n",
        "        vol_sagit = vol_sagit[:,pad:-pad,pad:-pad]\n",
        "        #vol_sagit = np.dot(np.divide((vol_sagit - vol_sagit.min()) , (vol_sagit.max() - vol_sagit.min())) , MAX_PIXEL_VAL)\n",
        "        #vol_sagit = np.divide((vol_sagit - MEAN) , STDDEV)\n",
        "        #vol_sagit = np.stack((vol_sagit,)*3, axis=1)\n",
        "        vol_sagit = preprocess(vol_sagit)\n",
        "        \n",
        "        \n",
        "        vol_sagit_tensor = torch.FloatTensor(vol_sagit)\n",
        "        \n",
        "        # coronal\n",
        "        pad = int((vol_coron.shape[2] - INPUT_DIM)/2)\n",
        "        vol_coron = vol_coron[:,pad:-pad,pad:-pad]\n",
        "        #vol_coron = np.dot(np.divide((vol_coron - vol_coron.min()) , (vol_coron.max() - vol_coron.min())) , MAX_PIXEL_VAL)\n",
        "        #vol_coron = np.divide((vol_coron - MEAN) , STDDEV)\n",
        "        #vol_coron = np.stack((vol_coron,)*3, axis=1)\n",
        "        vol_coron = preprocess(vol_coron)\n",
        "        \n",
        "        vol_coron_tensor = torch.FloatTensor(vol_coron)\n",
        "        \n",
        "\n",
        "        label_tensor = torch.FloatTensor([self.labels[index]])\n",
        "\n",
        "        return vol_axial_tensor, vol_sagit_tensor, vol_coron_tensor, label_tensor , self.abnormal_labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIwRg8jxXlGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "def compare():\n",
        "    data = pd.read_csv('/content/drive/My Drive/MRNet-v1.0/train-acl.csv' , header=None) \n",
        "\n",
        "    for i in range(len(train_dataset)):\n",
        "      if train_dataset.labels[i] != data[1][int(train_dataset.paths[i][:4])]:\n",
        "        print(\"Not Equal\")\n",
        "        break\n",
        "      else:\n",
        "        print(i , train_dataset.labels[i] , data[1][int(train_dataset.paths[i][:4])] ,train_dataset.abnormal_labels[i] ,  train_dataset.paths[i] )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08VxH_bJrjRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(task, use_gpu):\n",
        "  train_dir = \"/content/drive/My Drive/MRNet-v1.0/train\"\n",
        "  valid_dir = \"/content/drive/My Drive/MRNet-v1.0/valid\"\n",
        "\n",
        "  train_dataset = Dataset(train_dir, task, use_gpu  )\n",
        "  valid_dataset = Dataset(valid_dir, task, use_gpu )\n",
        "\n",
        "  train_loader = data.DataLoader(train_dataset, batch_size=1, num_workers=11, shuffle=True)\n",
        "  valid_loader = data.DataLoader(valid_dataset, batch_size=1, num_workers=11, shuffle=False)\n",
        "\n",
        "  return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP8J4eQjsGQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(model, loader, train=False, optimizer=None,abnormal_model_path=None):\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        if abnormal_model_path:\n",
        "            abnormal_model = MRI_alex()\n",
        "            state_dict = torch.load(abnormal_model_path)\n",
        "            abnormal_model.load_state_dict(state_dict)\n",
        "            abnormal_model.cuda()\n",
        "            abnormal_model.eval()\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in tqdm(loader):\n",
        "        vol_axial, vol_sagit, vol_coron, label, abnormal = batch\n",
        "        if train:\n",
        "            if abnormal_model_path and not abnormal:\n",
        "                continue\n",
        "            optimizer.zero_grad()\n",
        "        if loader.dataset.use_gpu:\n",
        "            vol_axial, vol_sagit, vol_coron = vol_axial.cuda(), vol_sagit.cuda(), vol_coron.cuda()\n",
        "            label = label.cuda()\n",
        "        vol_axial, vol_sagit, vol_coron = Variable(vol_axial), Variable(vol_sagit), Variable(vol_coron)\n",
        "        label = Variable(label)\n",
        "\n",
        "        logit = model.forward(vol_axial, vol_sagit, vol_coron)\n",
        "\n",
        "        loss = loader.dataset.weighted_loss(logit, label)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        pred = torch.sigmoid(logit)\n",
        "\n",
        "        pred_npy = pred.data.cpu().numpy()[0][0]\n",
        "\n",
        "        if abnormal_model_path and not train:\n",
        "            abnormal_logit = abnormal_model.forward(vol_axial,vol_sagit,vol_coron)\n",
        "            abnormal_pred = torch.sigmoid(abnormal_logit)\n",
        "            abnormal_pred_npy = abnormal_pred.data.cpu().numpy()[0][0]\n",
        "            pred_npy = pred_npy * abnormal_pred_npy\n",
        "\n",
        "        label_npy = label.data.cpu().numpy()[0][0]\n",
        "\n",
        "        preds.append(pred_npy)\n",
        "        labels.append(label_npy)\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    \n",
        "    fpr, tpr, threshold = metrics.roc_curve(labels, preds)\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    if abnormal_model_path and not train:\n",
        "        del abnormal_model\n",
        "\n",
        "    return avg_loss, auc, preds, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD-iYQhgsJmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(split, model_path, diagnosis, use_gpu):\n",
        "    train_loader, valid_loader, test_loader = load_data(diagnosis, use_gpu)\n",
        "\n",
        "    model = MRNet()\n",
        "    state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    if use_gpu:\n",
        "        model = model.cuda()\n",
        "\n",
        "    if split == 'train':\n",
        "        loader = train_loader\n",
        "    elif split == 'valid':\n",
        "        loader = valid_loader\n",
        "    elif split == 'test':\n",
        "        loader = test_loader\n",
        "    else:\n",
        "        raise ValueError(\"split must be 'train', 'valid', or 'test'\")\n",
        "\n",
        "    loss, auc, preds, labels = run_model(model, loader)\n",
        "\n",
        "    print(f'{split} loss: {loss:0.4f}')\n",
        "    print(f'{split} AUC: {auc:0.4f}')\n",
        "\n",
        "    return preds, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AdBSim3sNwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(rundir, task, epochs, learning_rate, use_gpu,model,abnormal_model_path=None):\n",
        "    train_loader, valid_loader = load_data(task, use_gpu)\n",
        "    \n",
        "    model = model\n",
        "    '''for dirpath, dirnames, files in os.walk(rundir):\n",
        "        if not files:\n",
        "            break\n",
        "        max_epoch = 0\n",
        "        model_path = None\n",
        "        for fname in files:\n",
        "            if fname.endswith(\".json\"):\n",
        "                continue\n",
        "            ep = int(fname[27:])\n",
        "            if ep >= max_epoch:\n",
        "                max_epoch = ep\n",
        "                model_path = os.path.join(dirpath, fname)\n",
        "        \n",
        "        if model_path:\n",
        "            state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n",
        "            model.load_state_dict(state_dict)\n",
        "'''\n",
        "    if use_gpu:\n",
        "        model = model.cuda()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.3, threshold=1e-4)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        change = datetime.now() - start_time\n",
        "        print('starting epoch {}. time passed: {}  : lr = {} '.format(epoch+1, str(change) , learning_rate))\n",
        "        \n",
        "        train_loss, train_auc, _, _ = run_model(model, train_loader, train=True, optimizer=optimizer , abnormal_model_path=abnormal_model_path)\n",
        "\n",
        "        print(f'train loss: {train_loss:0.4f}')\n",
        "        print(f'train AUC: {train_auc:0.4f}')\n",
        "\n",
        "        val_loss, val_auc, _, _ = run_model(model, valid_loader , abnormal_model_path=abnormal_model_path)\n",
        "        \n",
        "        print(f'valid loss: {val_loss:0.4f}')\n",
        "        print(f'valid AUC: {val_auc:0.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inhU6nlQsXdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e97eada47918456b950d4cb96b39d9a9",
            "0bc4d8f8365a45c2b078c24d26af8855",
            "272c38bfa84d4666bf1fe9e5d1c3f23d",
            "94756e74dc3143319a412f6a7baf1b96",
            "104dd591decb473bbd0fe13cd6c2cb6b",
            "0946af67252f467b80103237d76cd54e",
            "8475935f96f14a9a994a95702c6137a0",
            "c57533049ccd4720ad5fa98272afbdee"
          ]
        },
        "outputId": "2e0efa6c-f6cb-4825-83af-82df4b0de564"
      },
      "source": [
        "model_men=MRI_alex(training=True)\n",
        "model_meniscus = train('/content/drive/My Drive/MRNet-v1.0',task='meniscus',epochs=50,learning_rate=1e-06,use_gpu=True,model=model_men , abnormal_model_path='/content/drive/My Drive/MRNet-v1.0/Untitled Folder/abnormal.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e97eada47918456b950d4cb96b39d9a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "starting epoch 1. time passed: 0:00:00.000014  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [06:06<00:00,  3.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.3473\n",
            "train AUC: 0.5329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:44<00:00,  2.73it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3654\n",
            "valid AUC: 0.7661\n",
            "starting epoch 2. time passed: 0:07:18.021386  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:13<00:00,  3.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.3322\n",
            "train AUC: 0.6088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:39<00:00,  3.03it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3471\n",
            "valid AUC: 0.7704\n",
            "starting epoch 3. time passed: 0:13:27.232877  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:16<00:00,  3.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.3217\n",
            "train AUC: 0.6781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:39<00:00,  3.02it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3370\n",
            "valid AUC: 0.7740\n",
            "starting epoch 4. time passed: 0:19:40.380436  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:17<00:00,  3.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.3126\n",
            "train AUC: 0.7251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.99it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3310\n",
            "valid AUC: 0.7774\n",
            "starting epoch 5. time passed: 0:25:54.214860  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:26<00:00,  3.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.3036\n",
            "train AUC: 0.7596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.96it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3445\n",
            "valid AUC: 0.7831\n",
            "starting epoch 6. time passed: 0:32:18.149633  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:19<00:00,  3.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.2978\n",
            "train AUC: 0.7827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.99it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3332\n",
            "valid AUC: 0.7842\n",
            "starting epoch 7. time passed: 0:38:34.139549  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:20<00:00,  3.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.2909\n",
            "train AUC: 0.7987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.96it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3282\n",
            "valid AUC: 0.7837\n",
            "starting epoch 8. time passed: 0:44:52.578079  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:20<00:00,  3.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.2832\n",
            "train AUC: 0.8263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.98it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3130\n",
            "valid AUC: 0.7828\n",
            "starting epoch 9. time passed: 0:51:09.829455  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:22<00:00,  3.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.2786\n",
            "train AUC: 0.8276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.97it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3158\n",
            "valid AUC: 0.7873\n",
            "starting epoch 10. time passed: 0:57:29.096036  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:20<00:00,  3.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.2722\n",
            "train AUC: 0.8439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.98it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3117\n",
            "valid AUC: 0.7854\n",
            "starting epoch 11. time passed: 1:03:46.133420  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:21<00:00,  3.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.2659\n",
            "train AUC: 0.8553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:39<00:00,  3.01it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3101\n",
            "valid AUC: 0.7868\n",
            "starting epoch 12. time passed: 1:10:04.593353  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:22<00:00,  3.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.2629\n",
            "train AUC: 0.8623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.95it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3171\n",
            "valid AUC: 0.7907\n",
            "starting epoch 13. time passed: 1:16:23.971370  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:21<00:00,  3.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.2581\n",
            "train AUC: 0.8702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.98it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3238\n",
            "valid AUC: 0.7930\n",
            "starting epoch 14. time passed: 1:22:41.724447  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1130/1130 [05:20<00:00,  3.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss: 0.2535\n",
            "train AUC: 0.8770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:40<00:00,  2.98it/s]\n",
            "  0%|          | 0/1130 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid loss: 0.3051\n",
            "valid AUC: 0.7882\n",
            "starting epoch 15. time passed: 1:28:59.224809  : lr = 1e-06 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|â–Ž         | 34/1130 [00:16<03:41,  4.94it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piOBvoUGa77j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_men.state_dict() ,'/content/drive/My Drive/MRNet-v1.0/Untitled Folder/model_men.pt' )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}