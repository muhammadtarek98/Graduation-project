{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MRnet_Models_Alexnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammadtarek98/Graduation-project/blob/master/notebook/MRnet_Models_Alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sNGHUei1q4jv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "dd02cdac-95b8-48a4-99a1-61f058139ee9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_E0ZkySu6eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "724629a0-e94e-48c4-b0cb-894d13ecde8c"
      },
      "source": [
        "!pip install git+https://github.com/ncullen93/torchsample\n",
        "!pip install tensorboardX \n",
        "#!pip install --upgrade torch\n",
        "!pip install torch==1.5.1+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!wget https://gist.githubusercontent.com/archie9211/ae3c8411da88ae8b2a05b0ee1a4fd412/raw/ee1a6e78fc498ad6d4830cd2eb6033839235ea8a/colab-ssh-jupyter.sh\n",
        "!pip install -U git+https://github.com/pytorch/vision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ncullen93/torchsample\n",
            "  Cloning https://github.com/ncullen93/torchsample to /tmp/pip-req-build-w2xyznnm\n",
            "  Running command git clone -q https://github.com/ncullen93/torchsample /tmp/pip-req-build-w2xyznnm\n",
            "Building wheels for collected packages: torchsample\n",
            "  Building wheel for torchsample (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchsample: filename=torchsample-0.1.3-cp36-none-any.whl size=43417 sha256=5bbcddac37a8f80e25ba3787dc4dd707471f2cd31c7885251f816454006e2599\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f8imob58/wheels/88/c7/72/14cd9a173eed1e29d0b17d866e7d9ee511d31a834aedd27489\n",
            "Successfully built torchsample\n",
            "Installing collected packages: torchsample\n",
            "Successfully installed torchsample-0.1.3\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (47.3.1)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision==0.6.0+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0+cu101) (7.0.0)\n",
            "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101\n",
            "--2020-06-21 13:29:35--  https://gist.githubusercontent.com/archie9211/ae3c8411da88ae8b2a05b0ee1a4fd412/raw/ee1a6e78fc498ad6d4830cd2eb6033839235ea8a/colab-ssh-jupyter.sh\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1125 (1.1K) [text/plain]\n",
            "Saving to: ‘colab-ssh-jupyter.sh’\n",
            "\n",
            "colab-ssh-jupyter.s 100%[===================>]   1.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-21 13:29:35 (59.3 MB/s) - ‘colab-ssh-jupyter.sh’ saved [1125/1125]\n",
            "\n",
            "Collecting git+https://github.com/pytorch/vision\n",
            "  Cloning https://github.com/pytorch/vision to /tmp/pip-req-build-wtjhob9q\n",
            "  Running command git clone -q https://github.com/pytorch/vision /tmp/pip-req-build-wtjhob9q\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0a0+cd2b7f0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0a0+cd2b7f0) (1.5.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0a0+cd2b7f0) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==0.7.0a0+cd2b7f0) (0.16.0)\n",
            "Building wheels for collected packages: torchvision\n",
            "  Building wheel for torchvision (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchvision: filename=torchvision-0.7.0a0+cd2b7f0-cp36-cp36m-linux_x86_64.whl size=7915597 sha256=32cfef698cc4a8d26706bf988a0151c8c0207b43ba05b2493093f1d45dd65386\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ydp3t4oh/wheels/46/b1/7a/c6b6a2d8276d68c5231436044279cd0cd3338b6560b2c14336\n",
            "Successfully built torchvision\n",
            "Installing collected packages: torchvision\n",
            "  Found existing installation: torchvision 0.6.0+cu101\n",
            "    Uninstalling torchvision-0.6.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Successfully installed torchvision-0.7.0a0+cd2b7f0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "utDm6bILrCYz",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.autograd import Variable\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bN8am-ngrQ8S",
        "colab": {}
      },
      "source": [
        "class MRNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = models.alexnet(pretrained=True)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.squeeze(x, dim=0) # only batch size 1 supported\n",
        "        x = self.model.features(x)\n",
        "        x = self.gap(x).view(x.size(0), -1)\n",
        "        x = torch.max(x, 0, keepdim=True)[0]\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fX2A_1HMrVme",
        "colab": {}
      },
      "source": [
        "class MRI_alex(nn.Module):\n",
        "  def __init__(self, training=True):\n",
        "    super().__init__()\n",
        "    self.axial_net = models.alexnet(pretrained=training)\n",
        "    self.sagit_net = models.alexnet(pretrained=training)\n",
        "    self.coron_net = models.alexnet(pretrained=training)\n",
        "\n",
        "    self.gap_axial = nn.AdaptiveAvgPool2d(1)\n",
        "    self.gap_sagit = nn.AdaptiveAvgPool2d(1) \n",
        "    self.gap_coron = nn.AdaptiveAvgPool2d(1)\n",
        "    self.classifier = nn.Linear(3*256, 1)\n",
        "\n",
        "  def forward(self,vol_axial, vol_sagit, vol_coron):\n",
        "    vol_axial = torch.squeeze(vol_axial, dim=0)\n",
        "    vol_sagit = torch.squeeze(vol_sagit, dim=0)\n",
        "    vol_coron = torch.squeeze(vol_coron, dim=0)\n",
        "\n",
        "    vol_axial = self.axial_net.features(vol_axial)\n",
        "    vol_sagit = self.sagit_net.features(vol_sagit)\n",
        "    vol_coron = self.coron_net.features(vol_coron)\n",
        "\n",
        "    vol_axial = self.gap_axial(vol_axial).view(vol_axial.size(0), -1)\n",
        "    x = torch.max(vol_axial, 0, keepdim=True)[0]\n",
        "\n",
        "    vol_sagit = self.gap_sagit(vol_sagit).view(vol_sagit.size(0), -1)\n",
        "    y = torch.max(vol_sagit, 0, keepdim=True)[0]\n",
        "\n",
        "    vol_coron = self.gap_coron(vol_coron).view(vol_coron.size(0), -1)\n",
        "    z = torch.max(vol_coron, 0, keepdim=True)[0]\n",
        "\n",
        "    w = torch.cat((x, y, z), 1)\n",
        "    out = self.classifier(w)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKYynazQVHIU",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomAffine(25, translate=(0.1, 0.1)),\n",
        "            transforms.ToTensor()\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7UT8KmaYVztF",
        "colab": {}
      },
      "source": [
        "valid_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor()\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_-7nLcYmWTlq",
        "colab": {}
      },
      "source": [
        "def preprocess(series):\n",
        "   series = torch.tensor(np.stack((series,)*3, axis=1))\n",
        "   series = np.dot(np.divide((series - series.min()) , (series.max() - series.min())) , MAX_PIXEL_VAL)\n",
        "   series = np.divide((series - MEAN) , STDDEV)\n",
        "   return series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KVX6JB_NriNI",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 224\n",
        "MAX_PIXEL_VAL = 255\n",
        "MEAN = 58.09\n",
        "STDDEV = 49.73\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, datadir, tear_type, use_gpu , transform=None):\n",
        "        super().__init__()\n",
        "        self.use_gpu = use_gpu\n",
        "        label_dict = {}\n",
        "        self.paths = []\n",
        "        self.transform = transform\n",
        "        \n",
        "        abnormal_label_dict = {}\n",
        "        if datadir[-1]==\"/\":\n",
        "            datadir = datadir[:-1]\n",
        "        self.datadir = datadir\n",
        "        for i, line in enumerate(open(datadir+'-'+tear_type+'.csv').readlines()):\n",
        "            line = line.strip().split(',')\n",
        "            filename = line[0]\n",
        "            label = line[1]\n",
        "            label_dict[filename] = int(label)\n",
        "        \n",
        "\n",
        "        for i, line in enumerate(open(datadir+'-'+\"abnormal\"+'.csv').readlines()):\n",
        "            line = line.strip().split(',')\n",
        "            filename = line[0]\n",
        "            label = line[1]\n",
        "            abnormal_label_dict[filename] = int(label)\n",
        "\n",
        "        for filename in os.listdir(os.path.join(datadir, \"axial\")):\n",
        "            if filename.endswith(\".npy\"):\n",
        "                self.paths.append(filename)\n",
        "        \n",
        "        self.labels = [label_dict[path.split(\".\")[0]] for path in self.paths]\n",
        "        self.abnormal_labels = [abnormal_label_dict[path.split(\".\")[0]] for path in self.paths]\n",
        "\n",
        "        #neg_weight = np.mean(self.labels)\n",
        "        #self.weights = [neg_weight, 1 - neg_weight]\n",
        "\n",
        "        if tear_type != \"abnormal\":\n",
        "            temp_labels = [self.labels[i] for i in range(len(self.labels)) if self.abnormal_labels[i]==1]\n",
        "            neg_weight = np.mean(temp_labels)\n",
        "        else:\n",
        "            neg_weight = np.mean(self.labels)\n",
        "        \n",
        "        self.weights = [neg_weight, 1 - neg_weight]\n",
        "    \n",
        "\n",
        "    def weighted_loss(self, prediction, target):\n",
        "        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n",
        "        weights_tensor = torch.FloatTensor(weights_npy)\n",
        "        if self.use_gpu:\n",
        "            weights_tensor = weights_tensor.cuda()\n",
        "        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n",
        "        return loss\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.paths[index]\n",
        "        vol_axial = np.load(os.path.join(self.datadir, \"axial\", filename))\n",
        "        vol_sagit = np.load(os.path.join(self.datadir, \"sagittal\", filename))\n",
        "        vol_coron = np.load(os.path.join(self.datadir, \"coronal\", filename))\n",
        "\n",
        "\n",
        "        # axial\n",
        "        pad = int((vol_axial.shape[2] - INPUT_DIM)/2)\n",
        "        vol_axial = vol_axial[:,pad:-pad,pad:-pad]\n",
        "        #vol_axial = np.dot(np.divide((vol_axial - vol_axial.min()) , (vol_axial.max() - vol_axial.min())) , MAX_PIXEL_VAL)\n",
        "        #vol_axial = np.divide((vol_axial - MEAN) , STDDEV)\n",
        "        #vol_axial = np.stack((vol_axial,)*3, axis=1)\n",
        "        vol_axial = preprocess(vol_axial)\n",
        "        \n",
        "        vol_axial_tensor = torch.FloatTensor(vol_axial)\n",
        "          \n",
        "        \n",
        "        # sagittal\n",
        "        pad = int((vol_sagit.shape[2] - INPUT_DIM)/2)\n",
        "        vol_sagit = vol_sagit[:,pad:-pad,pad:-pad]\n",
        "        #vol_sagit = np.dot(np.divide((vol_sagit - vol_sagit.min()) , (vol_sagit.max() - vol_sagit.min())) , MAX_PIXEL_VAL)\n",
        "        #vol_sagit = np.divide((vol_sagit - MEAN) , STDDEV)\n",
        "        #vol_sagit = np.stack((vol_sagit,)*3, axis=1)\n",
        "        vol_sagit = preprocess(vol_sagit)\n",
        "        \n",
        "        \n",
        "        vol_sagit_tensor = torch.FloatTensor(vol_sagit)\n",
        "        \n",
        "        # coronal\n",
        "        pad = int((vol_coron.shape[2] - INPUT_DIM)/2)\n",
        "        vol_coron = vol_coron[:,pad:-pad,pad:-pad]\n",
        "        #vol_coron = np.dot(np.divide((vol_coron - vol_coron.min()) , (vol_coron.max() - vol_coron.min())) , MAX_PIXEL_VAL)\n",
        "        #vol_coron = np.divide((vol_coron - MEAN) , STDDEV)\n",
        "        #vol_coron = np.stack((vol_coron,)*3, axis=1)\n",
        "        vol_coron = preprocess(vol_coron)\n",
        "        \n",
        "        vol_coron_tensor = torch.FloatTensor(vol_coron)\n",
        "        \n",
        "\n",
        "        label_tensor = torch.FloatTensor([self.labels[index]])\n",
        "\n",
        "        return vol_axial_tensor, vol_sagit_tensor, vol_coron_tensor, label_tensor , self.abnormal_labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vIwRg8jxXlGo",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "def compare():\n",
        "    data = pd.read_csv('/content/drive/My Drive/MRNet-v1.0/train-acl.csv' , header=None) \n",
        "\n",
        "    for i in range(len(train_dataset)):\n",
        "      if train_dataset.labels[i] != data[1][int(train_dataset.paths[i][:4])]:\n",
        "        print(\"Not Equal\")\n",
        "        break\n",
        "      else:\n",
        "        print(i , train_dataset.labels[i] , data[1][int(train_dataset.paths[i][:4])] ,train_dataset.abnormal_labels[i] ,  train_dataset.paths[i] )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "08VxH_bJrjRQ",
        "colab": {}
      },
      "source": [
        "def load_data(task, use_gpu):\n",
        "  train_dir = \"/content/drive/My Drive/MRNet-v1.0/train\"\n",
        "  valid_dir = \"/content/drive/My Drive/MRNet-v1.0/valid\"\n",
        "\n",
        "  train_dataset = Dataset(train_dir, task, use_gpu  )\n",
        "  valid_dataset = Dataset(valid_dir, task, use_gpu )\n",
        "\n",
        "  train_loader = data.DataLoader(train_dataset, batch_size=1, num_workers=11, shuffle=True)\n",
        "  valid_loader = data.DataLoader(valid_dataset, batch_size=1, num_workers=11, shuffle=False)\n",
        "\n",
        "  return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rP8J4eQjsGQI",
        "colab": {}
      },
      "source": [
        "def run_model(model, loader, train=False, optimizer=None,abnormal_model_path=None):\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        if abnormal_model_path:\n",
        "            abnormal_model = MRI_alex()\n",
        "            state_dict = torch.load(abnormal_model_path)\n",
        "            abnormal_model.load_state_dict(state_dict)\n",
        "            abnormal_model.cuda()\n",
        "            abnormal_model.eval()\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in tqdm(loader):\n",
        "        vol_axial, vol_sagit, vol_coron, label, abnormal = batch\n",
        "        if train:\n",
        "            if abnormal_model_path and not abnormal:\n",
        "                continue\n",
        "            optimizer.zero_grad()\n",
        "        if loader.dataset.use_gpu:\n",
        "            vol_axial, vol_sagit, vol_coron = vol_axial.cuda(), vol_sagit.cuda(), vol_coron.cuda()\n",
        "            label = label.cuda()\n",
        "        vol_axial, vol_sagit, vol_coron = Variable(vol_axial), Variable(vol_sagit), Variable(vol_coron)\n",
        "        label = Variable(label)\n",
        "\n",
        "        logit = model.forward(vol_axial, vol_sagit, vol_coron)\n",
        "\n",
        "        loss = loader.dataset.weighted_loss(logit, label)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        pred = torch.sigmoid(logit)\n",
        "\n",
        "        pred_npy = pred.data.cpu().numpy()[0][0]\n",
        "\n",
        "        if abnormal_model_path and not train:\n",
        "            abnormal_logit = abnormal_model.forward(vol_axial,vol_sagit,vol_coron)\n",
        "            abnormal_pred = torch.sigmoid(abnormal_logit)\n",
        "            abnormal_pred_npy = abnormal_pred.data.cpu().numpy()[0][0]\n",
        "            pred_npy = pred_npy * abnormal_pred_npy\n",
        "\n",
        "        label_npy = label.data.cpu().numpy()[0][0]\n",
        "\n",
        "        preds.append(pred_npy)\n",
        "        labels.append(label_npy)\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    \n",
        "    fpr, tpr, threshold = metrics.roc_curve(labels, preds)\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    if abnormal_model_path and not train:\n",
        "        del abnormal_model\n",
        "\n",
        "    return avg_loss, auc, preds, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pD-iYQhgsJmY",
        "colab": {}
      },
      "source": [
        "def evaluate(split, model_path, diagnosis, use_gpu):\n",
        "    train_loader, valid_loader, test_loader = load_data(diagnosis, use_gpu)\n",
        "\n",
        "    model = MRNet()\n",
        "    state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    if use_gpu:\n",
        "        model = model.cuda()\n",
        "\n",
        "    if split == 'train':\n",
        "        loader = train_loader\n",
        "    elif split == 'valid':\n",
        "        loader = valid_loader\n",
        "    elif split == 'test':\n",
        "        loader = test_loader\n",
        "    else:\n",
        "        raise ValueError(\"split must be 'train', 'valid', or 'test'\")\n",
        "\n",
        "    loss, auc, preds, labels = run_model(model, loader)\n",
        "\n",
        "    print(f'{split} loss: {loss:0.4f}')\n",
        "    print(f'{split} AUC: {auc:0.4f}')\n",
        "\n",
        "    return preds, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3AdBSim3sNwu",
        "colab": {}
      },
      "source": [
        "def train(rundir, task, epochs, learning_rate, use_gpu,model,abnormal_model_path=None):\n",
        "    train_loader, valid_loader = load_data(task, use_gpu)\n",
        "    \n",
        "    model = model\n",
        "    '''for dirpath, dirnames, files in os.walk(rundir):\n",
        "        if not files:\n",
        "            break\n",
        "        max_epoch = 0\n",
        "        model_path = None\n",
        "        for fname in files:\n",
        "            if fname.endswith(\".json\"):\n",
        "                continue\n",
        "            ep = int(fname[27:])\n",
        "            if ep >= max_epoch:\n",
        "                max_epoch = ep\n",
        "                model_path = os.path.join(dirpath, fname)\n",
        "        \n",
        "        if model_path:\n",
        "            state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n",
        "            model.load_state_dict(state_dict)\n",
        "'''\n",
        "    if use_gpu:\n",
        "        model = model.cuda()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.3, threshold=1e-4)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        change = datetime.now() - start_time\n",
        "        print('starting epoch {}. time passed: {}  : lr = {} '.format(epoch+1, str(change) , learning_rate))\n",
        "        \n",
        "        train_loss, train_auc, _, _ = run_model(model, train_loader, train=True, optimizer=optimizer , abnormal_model_path=abnormal_model_path)\n",
        "\n",
        "        print(f'train loss: {train_loss:0.4f}')\n",
        "        print(f'train AUC: {train_auc:0.4f}')\n",
        "\n",
        "        val_loss, val_auc, _, _ = run_model(model, valid_loader , abnormal_model_path=abnormal_model_path)\n",
        "        \n",
        "        print(f'valid loss: {val_loss:0.4f}')\n",
        "        print(f'valid AUC: {val_auc:0.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E6LD5YINM9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_abnormal=MRI_alex(training=True)\n",
        "model_ab = train('/content/drive/My Drive/MRNet-v1.0',\n",
        "                       task='abnormal',\n",
        "                       epochs=50,\n",
        "                       learning_rate=1e-06,\n",
        "                       use_gpu=True,\n",
        "                       model=model_abnormal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7GyMl_mNM9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ACL=MRI_alex(training=True)\n",
        "model_meniscus = train('/content/drive/My Drive/MRNet-v1.0',\n",
        "                       task='ACL',\n",
        "                       epochs=50,\n",
        "                       learning_rate=1e-06,\n",
        "                       use_gpu=True,\n",
        "                       model=model_ACL, \n",
        "                       abnormal_model_path='/content/drive/My Drive/MRNet-v1.0/Untitled Folder/abnormal.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qwb4zleNM92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_men=MRI_alex(training=True)\n",
        "model_meniscus = train('/content/drive/My Drive/MRNet-v1.0',\n",
        "                       task='meniscus',\n",
        "                       epochs=50,\n",
        "                       learning_rate=1e-06,\n",
        "                       use_gpu=True,\n",
        "                       model=model_men, \n",
        "                       abnormal_model_path='/content/drive/My Drive/MRNet-v1.0/Untitled Folder/abnormal.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n5v9sEMNM97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_abnormal.state_dict(),'/content/drive/My Drive/MRNet-v1.0/Untitled Folder/abnormal.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfAvYxs7NM-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_ACL.state_dict() ,'/content/drive/My Drive/MRNet-v1.0/Untitled Folder/ACL.pt' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "piOBvoUGa77j",
        "colab": {}
      },
      "source": [
        "torch.save(model_men.state_dict() ,'/content/drive/My Drive/MRNet-v1.0/Untitled Folder/meniscus.pt' )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}