{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "sNGHUei1q4jv",
    "outputId": "dd02cdac-95b8-48a4-99a1-61f058139ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "s_E0ZkySu6eb",
    "outputId": "724629a0-e94e-48c4-b0cb-894d13ecde8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ncullen93/torchsample\n",
      "  Cloning https://github.com/ncullen93/torchsample to /tmp/pip-req-build-w2xyznnm\n",
      "  Running command git clone -q https://github.com/ncullen93/torchsample /tmp/pip-req-build-w2xyznnm\n",
      "Building wheels for collected packages: torchsample\n",
      "  Building wheel for torchsample (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchsample: filename=torchsample-0.1.3-cp36-none-any.whl size=43417 sha256=5bbcddac37a8f80e25ba3787dc4dd707471f2cd31c7885251f816454006e2599\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-f8imob58/wheels/88/c7/72/14cd9a173eed1e29d0b17d866e7d9ee511d31a834aedd27489\n",
      "Successfully built torchsample\n",
      "Installing collected packages: torchsample\n",
      "Successfully installed torchsample-0.1.3\n",
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 6.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (47.3.1)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.0\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.5.1+cu101\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
      "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
      "\u001b[?25hRequirement already satisfied: torchvision==0.6.0+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0+cu101) (7.0.0)\n",
      "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "  Found existing installation: torch 1.5.0+cu101\n",
      "    Uninstalling torch-1.5.0+cu101:\n",
      "      Successfully uninstalled torch-1.5.0+cu101\n",
      "Successfully installed torch-1.5.1+cu101\n",
      "--2020-06-21 13:29:35--  https://gist.githubusercontent.com/archie9211/ae3c8411da88ae8b2a05b0ee1a4fd412/raw/ee1a6e78fc498ad6d4830cd2eb6033839235ea8a/colab-ssh-jupyter.sh\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1125 (1.1K) [text/plain]\n",
      "Saving to: ‘colab-ssh-jupyter.sh’\n",
      "\n",
      "colab-ssh-jupyter.s 100%[===================>]   1.10K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-06-21 13:29:35 (59.3 MB/s) - ‘colab-ssh-jupyter.sh’ saved [1125/1125]\n",
      "\n",
      "Collecting git+https://github.com/pytorch/vision\n",
      "  Cloning https://github.com/pytorch/vision to /tmp/pip-req-build-wtjhob9q\n",
      "  Running command git clone -q https://github.com/pytorch/vision /tmp/pip-req-build-wtjhob9q\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0a0+cd2b7f0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0a0+cd2b7f0) (1.5.1+cu101)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0a0+cd2b7f0) (7.0.0)\n",
      "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==0.7.0a0+cd2b7f0) (0.16.0)\n",
      "Building wheels for collected packages: torchvision\n",
      "  Building wheel for torchvision (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchvision: filename=torchvision-0.7.0a0+cd2b7f0-cp36-cp36m-linux_x86_64.whl size=7915597 sha256=32cfef698cc4a8d26706bf988a0151c8c0207b43ba05b2493093f1d45dd65386\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ydp3t4oh/wheels/46/b1/7a/c6b6a2d8276d68c5231436044279cd0cd3338b6560b2c14336\n",
      "Successfully built torchvision\n",
      "Installing collected packages: torchvision\n",
      "  Found existing installation: torchvision 0.6.0+cu101\n",
      "    Uninstalling torchvision-0.6.0+cu101:\n",
      "      Successfully uninstalled torchvision-0.6.0+cu101\n",
      "Successfully installed torchvision-0.7.0a0+cd2b7f0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ncullen93/torchsample\n",
    "!pip install tensorboardX \n",
    "#!pip install --upgrade torch\n",
    "!pip install torch==1.5.1+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!wget https://gist.githubusercontent.com/archie9211/ae3c8411da88ae8b2a05b0ee1a4fd412/raw/ee1a6e78fc498ad6d4830cd2eb6033839235ea8a/colab-ssh-jupyter.sh\n",
    "!pip install -U git+https://github.com/pytorch/vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utDm6bILrCYz"
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bN8am-ngrQ8S"
   },
   "outputs": [],
   "source": [
    "class MRNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.alexnet(pretrained=True)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(x, dim=0) # only batch size 1 supported\n",
    "        x = self.model.features(x)\n",
    "        x = self.gap(x).view(x.size(0), -1)\n",
    "        x = torch.max(x, 0, keepdim=True)[0]\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fX2A_1HMrVme"
   },
   "outputs": [],
   "source": [
    "class MRI_alex(nn.Module):\n",
    "  def __init__(self, training=True):\n",
    "    super().__init__()\n",
    "    self.axial_net = models.alexnet(pretrained=training)\n",
    "    self.sagit_net = models.alexnet(pretrained=training)\n",
    "    self.coron_net = models.alexnet(pretrained=training)\n",
    "\n",
    "    self.gap_axial = nn.AdaptiveAvgPool2d(1)\n",
    "    self.gap_sagit = nn.AdaptiveAvgPool2d(1) \n",
    "    self.gap_coron = nn.AdaptiveAvgPool2d(1)\n",
    "    self.classifier = nn.Linear(3*256, 1)\n",
    "\n",
    "  def forward(self,vol_axial, vol_sagit, vol_coron):\n",
    "    vol_axial = torch.squeeze(vol_axial, dim=0)\n",
    "    vol_sagit = torch.squeeze(vol_sagit, dim=0)\n",
    "    vol_coron = torch.squeeze(vol_coron, dim=0)\n",
    "\n",
    "    vol_axial = self.axial_net.features(vol_axial)\n",
    "    vol_sagit = self.sagit_net.features(vol_sagit)\n",
    "    vol_coron = self.coron_net.features(vol_coron)\n",
    "\n",
    "    vol_axial = self.gap_axial(vol_axial).view(vol_axial.size(0), -1)\n",
    "    x = torch.max(vol_axial, 0, keepdim=True)[0]\n",
    "\n",
    "    vol_sagit = self.gap_sagit(vol_sagit).view(vol_sagit.size(0), -1)\n",
    "    y = torch.max(vol_sagit, 0, keepdim=True)[0]\n",
    "\n",
    "    vol_coron = self.gap_coron(vol_coron).view(vol_coron.size(0), -1)\n",
    "    z = torch.max(vol_coron, 0, keepdim=True)[0]\n",
    "\n",
    "    w = torch.cat((x, y, z), 1)\n",
    "    out = self.classifier(w)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKYynazQVHIU"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomAffine(25, translate=(0.1, 0.1)),\n",
    "            transforms.ToTensor()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UT8KmaYVztF"
   },
   "outputs": [],
   "source": [
    "valid_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ToTensor()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-7nLcYmWTlq"
   },
   "outputs": [],
   "source": [
    "def preprocess(series):\n",
    "   series = torch.tensor(np.stack((series,)*3, axis=1))\n",
    "   series = np.dot(np.divide((series - series.min()) , (series.max() - series.min())) , MAX_PIXEL_VAL)\n",
    "   series = np.divide((series - MEAN) , STDDEV)\n",
    "   return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVX6JB_NriNI"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 224\n",
    "MAX_PIXEL_VAL = 255\n",
    "MEAN = 58.09\n",
    "STDDEV = 49.73\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, datadir, tear_type, use_gpu , transform=None):\n",
    "        super().__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "        label_dict = {}\n",
    "        self.paths = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        abnormal_label_dict = {}\n",
    "        if datadir[-1]==\"/\":\n",
    "            datadir = datadir[:-1]\n",
    "        self.datadir = datadir\n",
    "        for i, line in enumerate(open(datadir+'-'+tear_type+'.csv').readlines()):\n",
    "            line = line.strip().split(',')\n",
    "            filename = line[0]\n",
    "            label = line[1]\n",
    "            label_dict[filename] = int(label)\n",
    "        \n",
    "\n",
    "        for i, line in enumerate(open(datadir+'-'+\"abnormal\"+'.csv').readlines()):\n",
    "            line = line.strip().split(',')\n",
    "            filename = line[0]\n",
    "            label = line[1]\n",
    "            abnormal_label_dict[filename] = int(label)\n",
    "\n",
    "        for filename in os.listdir(os.path.join(datadir, \"axial\")):\n",
    "            if filename.endswith(\".npy\"):\n",
    "                self.paths.append(filename)\n",
    "        \n",
    "        self.labels = [label_dict[path.split(\".\")[0]] for path in self.paths]\n",
    "        self.abnormal_labels = [abnormal_label_dict[path.split(\".\")[0]] for path in self.paths]\n",
    "\n",
    "        #neg_weight = np.mean(self.labels)\n",
    "        #self.weights = [neg_weight, 1 - neg_weight]\n",
    "\n",
    "        if tear_type != \"abnormal\":\n",
    "            temp_labels = [self.labels[i] for i in range(len(self.labels)) if self.abnormal_labels[i]==1]\n",
    "            neg_weight = np.mean(temp_labels)\n",
    "        else:\n",
    "            neg_weight = np.mean(self.labels)\n",
    "        \n",
    "        self.weights = [neg_weight, 1 - neg_weight]\n",
    "    \n",
    "\n",
    "    def weighted_loss(self, prediction, target):\n",
    "        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n",
    "        weights_tensor = torch.FloatTensor(weights_npy)\n",
    "        if self.use_gpu:\n",
    "            weights_tensor = weights_tensor.cuda()\n",
    "        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n",
    "        return loss\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.paths[index]\n",
    "        vol_axial = np.load(os.path.join(self.datadir, \"axial\", filename))\n",
    "        vol_sagit = np.load(os.path.join(self.datadir, \"sagittal\", filename))\n",
    "        vol_coron = np.load(os.path.join(self.datadir, \"coronal\", filename))\n",
    "\n",
    "\n",
    "        # axial\n",
    "        pad = int((vol_axial.shape[2] - INPUT_DIM)/2)\n",
    "        vol_axial = vol_axial[:,pad:-pad,pad:-pad]\n",
    "        #vol_axial = np.dot(np.divide((vol_axial - vol_axial.min()) , (vol_axial.max() - vol_axial.min())) , MAX_PIXEL_VAL)\n",
    "        #vol_axial = np.divide((vol_axial - MEAN) , STDDEV)\n",
    "        #vol_axial = np.stack((vol_axial,)*3, axis=1)\n",
    "        vol_axial = preprocess(vol_axial)\n",
    "        \n",
    "        vol_axial_tensor = torch.FloatTensor(vol_axial)\n",
    "          \n",
    "        \n",
    "        # sagittal\n",
    "        pad = int((vol_sagit.shape[2] - INPUT_DIM)/2)\n",
    "        vol_sagit = vol_sagit[:,pad:-pad,pad:-pad]\n",
    "        #vol_sagit = np.dot(np.divide((vol_sagit - vol_sagit.min()) , (vol_sagit.max() - vol_sagit.min())) , MAX_PIXEL_VAL)\n",
    "        #vol_sagit = np.divide((vol_sagit - MEAN) , STDDEV)\n",
    "        #vol_sagit = np.stack((vol_sagit,)*3, axis=1)\n",
    "        vol_sagit = preprocess(vol_sagit)\n",
    "        \n",
    "        \n",
    "        vol_sagit_tensor = torch.FloatTensor(vol_sagit)\n",
    "        \n",
    "        # coronal\n",
    "        pad = int((vol_coron.shape[2] - INPUT_DIM)/2)\n",
    "        vol_coron = vol_coron[:,pad:-pad,pad:-pad]\n",
    "        #vol_coron = np.dot(np.divide((vol_coron - vol_coron.min()) , (vol_coron.max() - vol_coron.min())) , MAX_PIXEL_VAL)\n",
    "        #vol_coron = np.divide((vol_coron - MEAN) , STDDEV)\n",
    "        #vol_coron = np.stack((vol_coron,)*3, axis=1)\n",
    "        vol_coron = preprocess(vol_coron)\n",
    "        \n",
    "        vol_coron_tensor = torch.FloatTensor(vol_coron)\n",
    "        \n",
    "\n",
    "        label_tensor = torch.FloatTensor([self.labels[index]])\n",
    "\n",
    "        return vol_axial_tensor, vol_sagit_tensor, vol_coron_tensor, label_tensor , self.abnormal_labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIwRg8jxXlGo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "def compare():\n",
    "    data = pd.read_csv('/content/drive/My Drive/MRNet-v1.0/train-acl.csv' , header=None) \n",
    "\n",
    "    for i in range(len(train_dataset)):\n",
    "      if train_dataset.labels[i] != data[1][int(train_dataset.paths[i][:4])]:\n",
    "        print(\"Not Equal\")\n",
    "        break\n",
    "      else:\n",
    "        print(i , train_dataset.labels[i] , data[1][int(train_dataset.paths[i][:4])] ,train_dataset.abnormal_labels[i] ,  train_dataset.paths[i] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08VxH_bJrjRQ"
   },
   "outputs": [],
   "source": [
    "def load_data(task, use_gpu):\n",
    "  train_dir = \"/content/drive/My Drive/MRNet-v1.0/train\"\n",
    "  valid_dir = \"/content/drive/My Drive/MRNet-v1.0/valid\"\n",
    "\n",
    "  train_dataset = Dataset(train_dir, task, use_gpu  )\n",
    "  valid_dataset = Dataset(valid_dir, task, use_gpu )\n",
    "\n",
    "  train_loader = data.DataLoader(train_dataset, batch_size=1, num_workers=11, shuffle=True)\n",
    "  valid_loader = data.DataLoader(valid_dataset, batch_size=1, num_workers=11, shuffle=False)\n",
    "\n",
    "  return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rP8J4eQjsGQI"
   },
   "outputs": [],
   "source": [
    "def run_model(model, loader, train=False, optimizer=None,abnormal_model_path=None):\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        if abnormal_model_path:\n",
    "            abnormal_model = MRI_alex()\n",
    "            state_dict = torch.load(abnormal_model_path)\n",
    "            abnormal_model.load_state_dict(state_dict)\n",
    "            abnormal_model.cuda()\n",
    "            abnormal_model.eval()\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch in tqdm(loader):\n",
    "        vol_axial, vol_sagit, vol_coron, label, abnormal = batch\n",
    "        if train:\n",
    "            if abnormal_model_path and not abnormal:\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "        if loader.dataset.use_gpu:\n",
    "            vol_axial, vol_sagit, vol_coron = vol_axial.cuda(), vol_sagit.cuda(), vol_coron.cuda()\n",
    "            label = label.cuda()\n",
    "        vol_axial, vol_sagit, vol_coron = Variable(vol_axial), Variable(vol_sagit), Variable(vol_coron)\n",
    "        label = Variable(label)\n",
    "\n",
    "        logit = model.forward(vol_axial, vol_sagit, vol_coron)\n",
    "\n",
    "        loss = loader.dataset.weighted_loss(logit, label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        pred = torch.sigmoid(logit)\n",
    "\n",
    "        pred_npy = pred.data.cpu().numpy()[0][0]\n",
    "\n",
    "        if abnormal_model_path and not train:\n",
    "            abnormal_logit = abnormal_model.forward(vol_axial,vol_sagit,vol_coron)\n",
    "            abnormal_pred = torch.sigmoid(abnormal_logit)\n",
    "            abnormal_pred_npy = abnormal_pred.data.cpu().numpy()[0][0]\n",
    "            pred_npy = pred_npy * abnormal_pred_npy\n",
    "\n",
    "        label_npy = label.data.cpu().numpy()[0][0]\n",
    "\n",
    "        preds.append(pred_npy)\n",
    "        labels.append(label_npy)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    \n",
    "    fpr, tpr, threshold = metrics.roc_curve(labels, preds)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    if abnormal_model_path and not train:\n",
    "        del abnormal_model\n",
    "\n",
    "    return avg_loss, auc, preds, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pD-iYQhgsJmY"
   },
   "outputs": [],
   "source": [
    "def evaluate(split, model_path, diagnosis, use_gpu):\n",
    "    train_loader, valid_loader, test_loader = load_data(diagnosis, use_gpu)\n",
    "\n",
    "    model = MRNet()\n",
    "    state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "\n",
    "    if split == 'train':\n",
    "        loader = train_loader\n",
    "    elif split == 'valid':\n",
    "        loader = valid_loader\n",
    "    elif split == 'test':\n",
    "        loader = test_loader\n",
    "    else:\n",
    "        raise ValueError(\"split must be 'train', 'valid', or 'test'\")\n",
    "\n",
    "    loss, auc, preds, labels = run_model(model, loader)\n",
    "\n",
    "    print(f'{split} loss: {loss:0.4f}')\n",
    "    print(f'{split} AUC: {auc:0.4f}')\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3AdBSim3sNwu"
   },
   "outputs": [],
   "source": [
    "def train(rundir, task, epochs, learning_rate, use_gpu,model,abnormal_model_path=None):\n",
    "    train_loader, valid_loader = load_data(task, use_gpu)\n",
    "    \n",
    "    model = model\n",
    "    '''for dirpath, dirnames, files in os.walk(rundir):\n",
    "        if not files:\n",
    "            break\n",
    "        max_epoch = 0\n",
    "        model_path = None\n",
    "        for fname in files:\n",
    "            if fname.endswith(\".json\"):\n",
    "                continue\n",
    "            ep = int(fname[27:])\n",
    "            if ep >= max_epoch:\n",
    "                max_epoch = ep\n",
    "                model_path = os.path.join(dirpath, fname)\n",
    "        \n",
    "        if model_path:\n",
    "            state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n",
    "            model.load_state_dict(state_dict)\n",
    "'''\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.3, threshold=1e-4)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        change = datetime.now() - start_time\n",
    "        print('starting epoch {}. time passed: {}  : lr = {} '.format(epoch+1, str(change) , learning_rate))\n",
    "        \n",
    "        train_loss, train_auc, _, _ = run_model(model, train_loader, train=True, optimizer=optimizer , abnormal_model_path=abnormal_model_path)\n",
    "\n",
    "        print(f'train loss: {train_loss:0.4f}')\n",
    "        print(f'train AUC: {train_auc:0.4f}')\n",
    "\n",
    "        val_loss, val_auc, _, _ = run_model(model, valid_loader , abnormal_model_path=abnormal_model_path)\n",
    "        \n",
    "        print(f'valid loss: {val_loss:0.4f}')\n",
    "        print(f'valid AUC: {val_auc:0.4f}')\n",
    "\n",
    "        scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abnormal=MRI_alex(training=True)\n",
    "model_ab = train('/content/drive/My Drive/MRNet-v1.0',\n",
    "                       task='abnormal',\n",
    "                       epochs=50,\n",
    "                       learning_rate=1e-06,\n",
    "                       use_gpu=True,\n",
    "                       model=model_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ACL=MRI_alex(training=True)\n",
    "model_meniscus = train('/content/drive/My Drive/MRNet-v1.0',\n",
    "                       task='ACL',\n",
    "                       epochs=50,\n",
    "                       learning_rate=1e-06,\n",
    "                       use_gpu=True,\n",
    "                       model=model_ACL, \n",
    "                       abnormal_model_path='/content/drive/My Drive/MRNet-v1.0/Untitled Folder/abnormal.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_men=MRI_alex(training=True)\n",
    "model_meniscus = train('/content/drive/My Drive/MRNet-v1.0',\n",
    "                       task='meniscus',\n",
    "                       epochs=50,\n",
    "                       learning_rate=1e-06,\n",
    "                       use_gpu=True,\n",
    "                       model=model_men, \n",
    "                       abnormal_model_path='/content/drive/My Drive/MRNet-v1.0/Untitled Folder/abnormal.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_abnormal.state_dict(),'/content/drive/My Drive/MRNet-v1.0/Untitled Folder/abnormal.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ACL.state_dict() ,'/content/drive/My Drive/MRNet-v1.0/Untitled Folder/ACL.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piOBvoUGa77j"
   },
   "outputs": [],
   "source": [
    "torch.save(model_men.state_dict() ,'/content/drive/My Drive/MRNet-v1.0/Untitled Folder/meniscus.pt' )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MRnet_Models Alexnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0946af67252f467b80103237d76cd54e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bc4d8f8365a45c2b078c24d26af8855": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "104dd591decb473bbd0fe13cd6c2cb6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "272c38bfa84d4666bf1fe9e5d1c3f23d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0946af67252f467b80103237d76cd54e",
      "max": 244418560,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_104dd591decb473bbd0fe13cd6c2cb6b",
      "value": 244418560
     }
    },
    "8475935f96f14a9a994a95702c6137a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94756e74dc3143319a412f6a7baf1b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c57533049ccd4720ad5fa98272afbdee",
      "placeholder": "​",
      "style": "IPY_MODEL_8475935f96f14a9a994a95702c6137a0",
      "value": " 233M/233M [00:22&lt;00:00, 10.7MB/s]"
     }
    },
    "c57533049ccd4720ad5fa98272afbdee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e97eada47918456b950d4cb96b39d9a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_272c38bfa84d4666bf1fe9e5d1c3f23d",
       "IPY_MODEL_94756e74dc3143319a412f6a7baf1b96"
      ],
      "layout": "IPY_MODEL_0bc4d8f8365a45c2b078c24d26af8855"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
